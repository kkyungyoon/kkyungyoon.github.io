---
title: "Boostcamp AI Tech_Week01_Day01"
date: 2024-08-05
layout: post
tags: [Naver Boostcamp, daily report]
---

# 강의 내용 복습  

## 1. [PyTorch] 01. PyTorch 기초

### 1) Pytorch를 사용하면 좋은 점을 배웠다.  
- 사용하기 간편하다.  
- 강력한 커뮤니티와 생태계가 존재한다.    
- 동적 계산 그래프가 가능하다.  
- 대규모 병렬 연산을 효율적으로 수행한다.  

<br>

### 2) Pytorch로 텐서를 만드는 법을 배웠다.
 1) 0차원 텐서 : argument가 scalar 형태  
 2) 1차원 텐서 : argument가 1차원 리스트 형태
 - dim-0에 집중(차원이 늘어날 때마다 축의 위치가 변경됨)    

 3) 2차원 텐서 : argument가 2차원 리스트 형태
 - dim-0이 새로운 행차원 축이 되고, 기존축은 dim-1이 됨  
 - 칸안의 값들은 gray scale에서의 밝기 정도  

 4) 3차원 텐서 : 2차원 텐서들을 포함하는 텐서  
 - 축 회전을 시켜서 각각의 요소별로 채널의 값을 합해서 색을 출력함 
 
 5) 4차원 텐서 : 시간이라는 축이 생김(영상생성 가능)  
<br><br>

## 2. [PyTorch] 02. Data type & Basic Functions

### 1) Pytorch 데이터 타입에 정수형, 실수형이 있고, 이를 만드는 법을 배웠다.  

#### 정수
1) 8비트 정수    
```
# 부호 없음
dtype = torch.uint8

# 부호 있음
dtype = torch.int8
```
2) 16비트 정수  
```
# 부호 있음
dtype = torch.int16
dtype = torch.short
```
4) 32비트 정수  
```
# 부호 있음
dtype = torch.int32
dtype = torch.int
```
5) 64비트 정수  
```
# 부호 있음
dtype = torch.int64
dtype = torch.long
```
<br>

#### 실수 
신경망 수치에 사용되기 때문에 가장 중요한 데이터 타입이다.  

1) 고정 소수점 수  
- 16비트 고정 소수점 수  
- 컴퓨터가 메모리를 감당하기 어려운 문제점 발생   

2) 부동 소수점 수  
- 가수부와 지수부로 나누는 정규화 진행  

```
# 32비트
dtype = torch.float32
dtype = torch.float
 
# 64비트 
dtype = torch.float64
dtype = torch.double
```  

<br><br>

### 3) 타입 캐스팅을 배웠다.  

32비트 부동 소수점 수로 변환하는 방법과 64비트 부동 소수점 수로 변환하는 방법이 있었다.   

```
# 32비트 부동 소수점 수로 변환
= 변환하고자하는tensor.float()

# 64비트 부동 소수점 수로 변환
= 변환하고자하는tensor.double()
```
<br>

### 4) Tensor의 요소를 반환하는 함수의 종류를 배웠다. 

```
- torch.max(tensor)  
- torch.min(tensor)  
- torch.prod(tensor) : 모두 곱한 값
- torch.mean(tensor)  
- torch.var(tensor) : 표본분산
- torch.std(tensor)  
```
<br>

### 5) Tensor의 특성을 확인하는 메서드를 배웠다.  

```
# 차원의 수
tensor_name.dim()
# 크기, 모양 확인  
tensor_name.size()
tensor_name.shape
# 요소의 총 개수
tensor_name.numel()  
```

<br><br>

## 3. [PyTorch] 03. Creating Tensors


### 1) 초기화된 Tensor를 생성하는 법을 배웠다.  
1) 0으로 초기화된 Tensor를 생성  
```
= torch.zeros(3)

# dim-0 (새로운 행차원), dim-1(기존 열차원)
= torch.zeros([2, 3])

# dim-0 (새로운 depth차원), dim-1(행), dim-2(열)
= torch.zeros([3, 2, 4])

# 사이즈 확인
print(c.size())

# 타입 확인
print(c.dtype)
```
<br>

2) 1으로 초기화된 Tensor를 생성 
```
= torch.ones(3)

# dim-0 (새로운 행차원), dim-1(기존 열차원)
= torch.ones([2, 3])

# dim-0 (새로운 depth차원), dim-1(행), dim-2(열)
= torch.ones([3, 2, 4])
```
<br><br>

### 2) 특정한 값으로 초기화된 Tensor 변환하는 것이 가능하다.  

```
# 크기와 자료형이 같은 0으로 초기화된 Tensor 
# 중요한 포인트 : 메모리 주소가 변하지않음
= torch.zeros_like(e)
# 크기와 자료형이 같은 1로 초기화된 Tensor
= torch.ones_like(e)
```
<br><br>

### 3) 난수로 초기화된 Tensor 생성도 가능하다.  

```
# [0, 1] 구간의 연속균등분포 난수 Tensor
= torch.rand(3) #요소가 3개인 1차원 텐서 생성
= torch.rand([2, 3])
# 표준정규분포 난수 Tensor 생성  
= torch.randn(3)
= torch.randn([2, 3])
# 크기와 자료형이 같은 [0, 1] 구간의 연속균등분포 난수 Tensor
torch.rand_like(k)
# 크기와 자료형이 같은 표준정규분포 난수 Tensor
torch.randn_like(i)
```
<br><br>

### 4) 지정된 범위 내에서 초기화된 Tensor 생성  
```
= torch.arange(start, end, step)
# step은 소수 간격으로도 가능 -> 데이터타입이 부동소수점 수로 나옴
```
<br><br>

### 5) 초기화되지 않은 Tensor 생성도 가능하다.  
```
# 초기화되지 않은 Tensor 생성
q = torch.empty(5)

# 그 텐서를 다른 데이터로 수정(메모리 주소는 그대로)
q.fill_(3.0)

torch.fill_(q, 3.0)
```
<br><br>

### 6) list, Numpy 데이터로부터 Tensor 생성도 가능하다.  
```
# list 생성 후, 텐서 생성하는 코드
= torch.tensor(list)

# 넘파이로부터 Tensor 생성
= torch.from_numpy(u).float()
# 넘파이로부터 생성된 텐서는 정수형이므로 실수형으로 타입 캐스팅
```
<br><br>  

### 7) CPU Tensor 생성도 가능하다.    

```
# 정수형 CPU Tensor 생성
w = torch.IntTensor([1,2,3,4,5])
torch.ByteTensor
torch.CharTensor
torch.ShortTensor
torch.LongTensor
# 실수형 CPU Tensor 생성
A, B, C, D, E = 1, 2, 3, 4, 5
x= torch.FloatTensor([A, B, C, D, E])
torch.DoubleTensor
```
<br><br>  

### 8) 생성 뿐만 아니라 복제도 가능하다.   
```
y = x.clone()
z = x.detach()
# x.detach는 x를 계산 그래프에서 분리하여 새로운 텐서 z에 저장한다는 것
# 자동미분때 다시 등장
```
<br><br>

### 9) CUDA Tensor 생성과 변환도 배웠다.   
```
# 디바이스 확인
tensor_name.device

# cuda를 사용할 수 있는 환경인지 확인
torch.cuda.is_available()

# cuda 디바이스 이름 확인
torch.cuda.get_device_name(device=0)

# 사용가능한 GPU 개수 확인
torch.cuda.device_count()

# tensor를 gpu에 할당

= torch.tensor([1,2,3,4,5]).to('cuda')
= torch.tensor([1,2,3,4,5]).cuda()

# GPU에 할당된 Tensor를 CPU로
= b.to('cpu')
= b.cpu()
```

<br><br>

***

# 피어세션 정리
- 그라운드 룰 정하기
- 줌 이론멘토링 시간 정하고 멘토님께 말씀드리기
- PyTorch 강의, 퀴즈, 과제 계획 세우기
- 정규과정 외에 추가공부 정하기
- 자기소개 ppt 내용 상의

***
<br><br>

# 학습회고

- 파이토치 데이터 타입에 대해 배우는 시간이었다

<br><br>